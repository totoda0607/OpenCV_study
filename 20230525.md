# 이미지 연산

* cv2.add(src1, src2, dest, mask, dtype) : src1과 src2 더하기
    * src1 : 첫 번째 입력 이미지
    * src2 : 두 번쨰 입력 이미지
    * dest(optional) : 출력 영상
    * mask(optional) : mask 값이 0이 아닌 픽셀만 연산
    * dtype(optional) : 출력 데이터 타입(dtype)
* cv2.subtract(src1, src2, dest, mask, dtype) : src1에서 src2 빼기
    * 모든 파라미터는 cv2.add()와 동일
* cv2.multiply(src1, src2, dest, scale, dtype) : src1과 src2 곱하기
    * scale(optional) : 연산 결과에 추가 연산할 값
* cv2.divide(src1, src2, dest, scale, dtype) : src1을 src2로 나누기
    * 모든 파라미터는 cv2.multiply()와 동일

* 255를 초과하는 경우 예를 들어서 200 + 100 = 300인 경우, 300-255-1 = 44로 치환을 한다 unit8타입의 값의 범위는 0 ~ 255이므로 255를 넘는 값은 다시 0부터 카운팅을 하기 때문이다.
* cv2.add() 함수를 활용하면 255를 초과하는 모든 값은 255로 반환한다. OpenCV에서는 0보다 작은 모든 값을 0으로 반환 한다.
* 곱하기와 나누기 연산도 255를 초과하거나 0보다 작은 값을 갖지 않고, 소수점은 갖지 않는다.

#### 이미지 합성
* numpy의 합이나 cv2.add() 함수만으로는 좋은 결과를 얻을 수 없다. 그 이유는 numpyt 합 연산을 수행하면 픽셀 값이 255가 넘는 경우 초과 값만을 갖기 때문에 이미지가 검은색에 가깝게 된다. cv2.add() 연산을 하면 대부분의 픽셀 값이 255 가까이 몰리는 현상이 발생하여 영상이 전체적으로 하얗게 된다.
* 두 이미지를 제대로 합성하려면 각각의 이미지에 가중치를 주고 합해야 한다.
    * cv2.addWeight(img1, alpha, img2, beta, gamma)
        * img1, img2 : 합성할 두 이미지
        * alpha : img1에 지정할 가중치(알파 값)
        * beta : img2에 지정할 가중치, 흔히 (1-alpha) 적용
        * gamma : 연산 결과에 가감할 상수, 흔히 0 적용

```python
import cv2
import numpy as np

alpha = 0.5 # 합성에 사용할 알파 값

#---① 합성에 사용할 영상 읽기
img1 = cv2.imread('../img/wing_wall.jpg')
img2 = cv2.imread('../img/yate.jpg')

# ---② NumPy 배열에 수식을 직접 연산해서 알파 블렌딩 적용
blended = img1 * alpha + img2 * (1-alpha)
blended = blended.astype(np.uint8) # 소수점 발생을 제거하기 위함
cv2.imshow('img1 * alpha + img2 * (1-alpha)', blended)

# ---③ addWeighted() 함수로 알파 블렌딩 적용
dst = cv2.addWeighted(img1, alpha, img2, (1-alpha), 0) 
cv2.imshow('cv2.addWeighted', dst)

cv2.waitKey(0)
cv2.destroyAllWindows()
```
> * 트렉바를 활용하여 알파를 조정하여 두개의 사진의 합성의 정도를 조절을 할 수도 있다.

#### 비트와이즈 연산
* OpenCV를 활용하여 두 이미지의 비트 단위 연산을 할 수도 있다.
* 비트와이즈 연산은 두 이미지를 합성할 때 특정 영역만 선택하거나 특정 영역만 제외하는 등의 선별적인 연산에 도움이 된다.

* OpenCV에서 제공하는 비트와이즈 연산 함수
    * cv2.bitwise_and(img1, img2, mask=None) : 각 픽셀에 대해 AND 연산
    * cv2.bitwise_or(img1, img2, mask=None) : 각 픽셀에 대해 OR 연산
    * cv2.bitwise_xor(img1, img2, mask=None) : 각 픽셀에 대해 XOR 연산
    * cv2.bitwise_not(img1, igm2, mask=None) : 각 픽셀에 대해 NOT 연산
* img1, img2는 연산을 할 이미지이며, 두 이미지는 동일한 shape를 가져야 한다. mask는 0이 아닌 픽셀만 연산하게 한다.

```python
import numpy as np, cv2
import matplotlib.pylab as plt

#--① 이미지 읽기
img = cv2.imread('../img/girl.jpg')

#--② 마스크 만들기
mask = np.zeros_like(img)
cv2.circle(mask, (150,140), 100, (255,255,255), -1)
#cv2.circle(대상이미지, (원점x, 원점y), 반지름, (색상), 채우기)

#--③ 마스킹
masked = cv2.bitwise_and(img, mask)

#--④ 결과 출력
cv2.imshow('original', img)
cv2.imshow('mask', mask)
cv2.imshow('masked', masked)
cv2.waitKey()
cv2.destroyAllWindows()
```
> * 이미지의 일부분을 원하는 모양으로 떼어내는 예제 코드이다.
> * 원본 이미지와 원 이미지를 AND 연산하면 100의 반지름을 가진 원안에 원본 이미지가 들어가있는 형태를 가지게 된다.
> * AND 연산은 Ture(0이 아닌 값)와 Ture(0이 아닌 값)이 합처진 부분만 True가 출력되기 때문이다.

#### 이미지 합성과 마스킹
* 일반적으로 하나의 이미지는 배경과 전경(배경이 아닌 실제 이미지)로 나뉜다.
* 예를 들어서 푸른 잔디에 강아지가 있는 이미지라고 치면, 푸른 잔디는 배경이고, 강아지는 전경이다.
* 배경은 A(알파, alpha)가 0이고, 전경은 A가 255이다. A가 0이면 투명하고, 255면 불투명하기 때문이다.
* _, mask = cv2.threshod(img_fg[:,:,3],1,255,cv2.THRESH_BINARY)를 호출하여 배경과 전경을 부리하는 마스크를 만든다.
* A가 1이상이면 255, 1미만이면 0으로 바꾸어주면 배경은 검은색, 전경은 흰색이 된다.
* mask_inv = cv2.bitwise_not(mask)는 mask_inv는 mask의 반대이다. 즉, 배경은 흰색, 전경은 검은색이다.
* 두 마스크를 활용 하면 이미지를 합성을 할 수 있다.

```python
import cv2
import numpy as np
import matplotlib.pylab as plt

#--① 크로마키 배경 영상과 합성할 배경 영상 읽기
img1 = cv2.imread('../img/man_chromakey.jpg')
img2 = cv2.imread('../img/street.jpg')

#--② ROI 선택을 위한 좌표 계산
height1, width1 = img1.shape[:2]
height2, width2 = img2.shape[:2]
x = (width2 - width1)//2
y = height2 - height1
w = x + width1
h = y + height1

#--③ 크로마키 배경 영상에서 크로마키 영역을 10픽셀 정도로 지정
chromakey = img1[:10, :10, :]
offset = 20

#--④ 크로마키 영역과 영상 전체를 HSV로 변경
hsv_chroma = cv2.cvtColor(chromakey, cv2.COLOR_BGR2HSV)
hsv_img = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)

#--⑤ 크로마키 영역의 H값에서 offset 만큼 여유를 두어서 범위 지정
# offset 값은 여러차례 시도 후 결정
#chroma_h = hsv_chroma[0]
chroma_h = hsv_chroma[:,:,0]
lower = np.array([chroma_h.min()-offset, 100, 100])
upper = np.array([chroma_h.max()+offset, 255, 255])

#--⑥ 마스크 생성 및 마스킹 후 합성
mask = cv2.inRange(hsv_img, lower, upper)
mask_inv = cv2.bitwise_not(mask)
roi = img2[y:h, x:w]
fg = cv2.bitwise_and(img1, img1, mask=mask_inv)
bg = cv2.bitwise_and(roi, roi, mask=mask)
img2[y:h, x:w] = fg + bg

#--⑦ 결과 출력
cv2.imshow('chromakey', img1)
cv2.imshow('added', img2)
cv2.waitKey()
cv2.destroyAllWindows()
```
> * 색상을 이용한 마스킹 방식을 크로마키(chroma key)라고 한다.
> * 위 코드는 초록색 배경을 두고 배우가 촬용한 뒤 나중에 초록색 배경은 다른 배경과 합성하는 방식이다.
> * 이미지 합성에는 블렌딩과 마스킹이 빌요하다. 블렌딩을 위한 알파 값 선택과 마스킹을 위한 좌표, 색상 선택에는 많은 시간이 소요된다.
> * OpenCV에서는 cv2.seamlessClone()이라는 함수가 있는데 이는 두 이미지의 특징을 살려 알아서 합성하는 기능이다.
      * dst = cv2.seamlessClone(src, dst, mask, coords, flags, output)
            * src : 입력 이미지, 일반적으로 전경
            * dst : 대상 이미지, 일반적으로 배경
            * mask : 마스크, src에서 합성하고자 하는 여역은 255, 나머지는 0
            * coords: src가 놓이기 원하는 dst의 좌표 (중앙)
            * flasg: 합성 방식
            * output(optional) : 합성 결과
> * flags는 입력 원본을 유지하는 cv2.NORMAL_CLONE과 입력과 대상을 혼합하는 cv2MIXED_CLONE이 있다.
> * 각 이미지를 cv2.seamlessClone() 함수를 활용하여 합성을 하면, 알파 값이나 마스크를 신경 쓰지 않아도 되기 때문에 편리하다.
> * cv2.NORMAL_CLONE일 때는 전경이 선명하지만 배경이 뭉개진다.
> * cv2.MIXED_CLONE일 떄는 전경이 다소 흐리지만, 배경이 잘 매칭이 되게 합성이된다.

# 캠을 활용한 사진 데이터 수집

```python
import cv2
import os


cap = cv2.VideoCapture(0)

flag_collecting = False
images_collected = 0
images_required = 50

directory = 'testing_demo'
os.mkdir(directory)


while True:
    ret, frame = cap.read()
    frame = cv2.flip(frame, 1)
    
    if images_collected == images_required:
        break

    cv2.rectangle(frame, (380,80),(620,320), (0, 0, 0), 3)

    if flag_collecting == True:
        sliced_frame = frame[80:320,380:620]
        save_path = os.path.join(directory, '{}.jpg'.format(images_collected + 1))
        cv2.imwrite(save_path, sliced_frame)
        images_collected += 1

    cv2.putText(frame, "Saved Images: {}".format(images_collected), (400, 50),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
    cv2.imshow("Data Collection", frame)
    
    k = cv2.waitKey(10)
    if k == ord('s'):
        flag_collecting = not flag_collecting
    if k == ord('q'):
        break

print(images_collected, "images saved to directory")
cap.release()
cv2.destroyAllWindows()
```

> * 실행을 하면 saved images의 칸이 같이 보인다.
> * 테두리 안에 저장하고자 하는 이미지의 물건을 놓고 's'를 누르면 50장의 이미지 파일이 저장된다.

# 배경 제거 (Background Subtraction)
> * 배경 제거 함수
>     * cv2.bgsegm.createBackgroundSubtractorMOG(history, nmixtures, backgroundRatio, noiseSigma)   
>           * history = 200 : 히스토리 길이   
>           * nmixtures = 5 : 가우시안 믹스처의 개수   
>           * backgroundRatio = 0.7 : 배경 비율   
>           * noiseSigma = 0 : 노이즈 강도 (0=자동)   
>           
>     * foregroundmask = backgroundsubtractor.apply(img, foregroundmask, learningRate)   
>           * img : 입력 영상   
>           * foregroundmask : 전경 마스크   
>           * learningRate = -1 : 배경 훈련 속도 (0 ~ 1, -1 : 자동)   
>           
>     * backgroundimage = backgroundsubtractor.getBackgroundimage(backgroundimage)   
>           * backgroundimage : 훈련용 배경 이미지   
>           
>     * cv2.createBackgroundSubtractorMOG2(history, varThreshold, detectShadows)   
>           * history = 500 : 히스토리 개수   
>           * varThreshold = 16 : 분산 임계 값   
>           * detectShadows = True : 그림자 표시   

* 캠을 활용한 배경 지우기
```python
import cv2
import numpy as np

cap = cv2.VideoCapture(0)
fgbg = cv2.createBackgroundSubtractorMOG2()

if cap.isOpened():
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        fgmask = fgbg.apply(frame)
        
        cv2.imshow('frame1', fgmask)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
cap.release()
cv2.destroyAllWindows()
```
