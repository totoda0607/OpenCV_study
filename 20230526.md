# ROS를 활용한 하드웨어간 통신

## ROS 설치
> 1. (https://wiki.ros.org) 로 접속
> 2. install -> ROS Noetic Ninjemys -> Ubuntu -> 위에서 부터 순차 진행
> 3. 1.2, 1.3, 1.4 맨윗줄, 1.4 Desktop-Full install 을 순차적으로 터미널에 입력하여 다운로드
> 4. 1.5 Environment setup의 source와 bash를 진행해준다.
> 5. 1.6 Dependencies for building package를 install 해준다.
> 6. 나머지 아래 3줄을 터미널창에 입력해준다.
> 7. catkin_ws 빌드

## 카메라 통신
> 1. catkin_create_pkg my_cam sensor_msgs cv_bridge rospy 로 패키지 생성
> * rosmsg show sensor_msgs/ (tap, tap) 으로 내부 정보 확인
> * rosmsg show sensor_msgs/Image 로 이미지 메세지 정보 확인
> * bridge가 ros 와 opencv의 연결 역할을 해준다.
> 2. scripts 폴더을 생성하고, my_cam_pub.py 파일 생성

```python
#!/usr/bin/python
#!-*- coding: utf-8 -*-

import rospy
import cv2
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError

rospy.init_node('my_cam_pub') # 노드를 지정
cap = cv2.VideoCapture(0) # 카메라 연결

if cap.IsOpened():
    pub = rospy.Publisher('my_image', Image, queue_size=10)
    bridge = CvBridge() # cv_bridge로 ros와 opencv의 데이터 변환에 사용된다.

    fps = cap.get(cv2.CAP_PROP_FPS)
    loop_rate = rospy.Rate(fps)

    while not rospy.is_shutdown():
        ret, frame = cap.read()
        if not ret:
            continue
        try:
            msg = bridge.cv2_to_imgmsg(frame, "bgr8") # frame을 img로 변환을 시켜준다. bgr8의 인코딩 사용
            pub.publish(msg)
        except CvBridgeError as e:
            print(e) # 변환 에러에대한 출력
        loop_rate.sleep()
```

> 3. my_cam_sub.py를 생성

```python
#!/usr/bin/python
#!-*- coding: utf-8 -*-

import rospy
import cv2
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError

bridge = CvBridge()

def imgCallback(msg):
    try:
        frame = bridge.imgmsg_to_cv2(msg, "bgr8")
    except CvBridgeError as e:
        print(e)
    
    cv2.imshow('my_image', frame)
    cv2.waitKey(3)

rospy.init_node('my_cam_sub')
sub = rospy.Subscriber('my_image', Image, imgCallback, queue_size=10)
rospy.spin()
cv2.destroyAllWindows()
```

> 4. CMakeLists.txt의 Install 부분의 catkin_install_python을 추가
> 5. cm으로 빌드 이후, roscore, rosrun my_cam my_cam_pub.py, rosrun my_cam my_cam_pub.py를 실행

## 동일 네트워크 연결

> 1. ifconfig 명령을 입력 (안될경우 : sudo apt install net-tools)
> 2. inet의 정보를 확인 : 127.0.0.1 은 나의 주소, 192.168.0.숫자 는 나의 다른 주소
> 3. eb로 bashrc접속 맨아래에 추가해주기.
```
export ROS_MASTER_URI=http://localhost:11311
export ROS_HOSTNAME=localhost

export ROS_MASTER_URI=http://192.168.0.44:11311
export ROS_HOSTNAME=192.168.0.64(내 inet를 입력)
```
> * 띄어쓰기는 '_'로 입력
> 6. rostopic echo /hello
> 7. rostopic pub /hello std_msgs/String 'dtat: hello'로 마스터에서 접속 host 로 전송된다.

#### 마스터에게 이미지 전송
> 1. 구별을 위해서 노드의 토픽의 이름을 수정한다.
>   * com64/my_image와 같이 namespace를 사용한다. 구분의 유용성을 높여준다.
> 2. 노드의 이름도 수정을 한다. rospy.init_node('my_cam_pub', anonymous=True) 노드이름뒤에 랜덤한 숫자생성
> 3. 마스터는 rosnode list로 연결을 확인을 할 수 있다.

# Teachable Machine활용
* 클래스픽 케이션 이라고 불려온다. 분류를 해주는 인공지능을 주로 이루고 있다.

> 1. https://teachablemachine.withgoogle.com 접속
> 2. 이미지 프로젝트로 생성
> epochs : 트레이닝의 양을 조절
> 3. previw 옆에 export model로 모델을 추출할 수 있다.
>       * Tensorflow.js : java를 사용할때 이용할 수 있다.
>       * Tensorflow.Lite : 안드로이드, TPU와 같은 소형화된 장비들에 사용된다.
>       * Tensorflow : 파이썬에 사용을 할때 쓴다.
> 4. Tensorflow -> download mymodel로 모델을 다운로드 해준다.
> 5. pip install tensorflow 로 텐서플로우를 다운로드 해준다.
> 6. 다운로드한 converted_keras.zip 압출을 풀어준다.
> 7. 압출 풀은 파일을 catkin_ws -> src -> my_cam에 model 폴더를 생성해서 옮겨준다.
>       * python3 -> import tensorflow를 사용하면 cudart_stub 학습용 프로그램의 유무를 확인할 수 있다.

### ROS에서 활용하기
> 1. scripts 디렉토리에 my_model.py 생성
> 2. Teachable Machine 다운로드에서의 코드 복사해 오기
```python
#!/usr/bin/python
#!-*- coding: utf-8 -*-

from keras.models import load_model  # TensorFlow is required for Keras to work
import cv2  # Install opencv-python
import numpy as np
import os

# Disable scientific notation for clarity
np.set_printoptions(suppress=True)

file_path = os.path.abspath(__file__) # ~/catkin_ws/src/my_cam/scripts/my_model.py
dir_path = os.path.dirname(file_path) # ~/catkin_ws/src/my_cam//scripts/
model_path = os.path.join(dir_path, "..", "model", "keras_model.h5") # ~/catkin_ws/src/../model/keras_model.h5
label_path = os.path.join(dir_path, "..", "model", "labels.txt") # ~/catkin_ws/src/../model/labels.txt
# Load the model
model = load_model(model_path, compile=False)

# Load the labels
class_names = open(label_path, "r").readlines()
# ["0, class_1", "1, class_2", "2, class_3"]

# CAMERA can be 0 or 1 based on default camera of your computer
camera = cv2.VideoCapture(0)

while True:
    # Grab the webcamera's image.
    ret, image_og = camera.read()

    # Resize the raw image into (224-height,224-width) pixels
    image = cv2.resize(image_og, (224, 224), interpolation=cv2.INTER_AREA)

    # Show the image in a window
    cv2.imshow("Webcam Image", image_og)

    # Make the image a numpy array and reshape it to the models input shape.
    image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)

    # Normalize the image array
    image = (image / 127.5) - 1 # model / 255 * 2 -1

    # Predicts the model
    prediction = model.predict(image)
    index = np.argmax(prediction)
    class_name = class_names[index]
    # ["0, class_1", "1, class_2", "2, class_3"]
    confidence_score = prediction[0][index]

    # Print prediction and confidence score
    print("Class:", class_name[2:], end="")
    print("Confidence Score:", str(np.round(confidence_score * 100))[:-2], "%")

    # Listen to the keyboard for presses.
    keyboard_input = cv2.waitKey(1)

    # 27 is the ASCII for the esc key on your keyboard.
    if keyboard_input == 27:
        break

camera.release()
cv2.destroyAllWindows()
```
> * import os : 운영체제와 관련 된 정보를 가지고 있다.
> * set_printoptions : 과학적 표기를 없애준다.
> * join 에는 여러개의 값이 들어간다.

##### 클래스 이름, 확률을 화면에 띄우기
* 확률이 애매한 경우 잘 모르겠다는 문구 출력
```python
#!/usr/bin/python
#!-*- coding: utf-8 -*-

from keras.models import load_model  # TensorFlow is required for Keras to work
import cv2  # Install opencv-python
import numpy as np
import os

# Disable scientific notation for clarity
np.set_printoptions(suppress=True)

file_path = os.path.abspath(__file__) # ~/catkin_ws/src/my_cam/scripts/my_model.py
dir_path = os.path.dirname(file_path) # ~/catkin_ws/src/my_cam//scripts/
model_path = os.path.join(dir_path, "..", "model", "keras_model.h5") # ~/catkin_ws/src/../model/keras_model.h5
label_path = os.path.join(dir_path, "..", "model", "labels.txt") # ~/catkin_ws/src/../model/labels.txt
# Load the model
model = load_model(model_path, compile=False)

# Load the labels
class_names = open(label_path, "r").readlines()
# ["0, class_1", "1, class_2", "2, class_3"]

# CAMERA can be 0 or 1 based on default camera of your computer
camera = cv2.VideoCapture(0)

while True:
    # Grab the webcamera's image.
    ret, image_og = camera.read()

    # Resize the raw image into (224-height,224-width) pixels
    image = cv2.resize(image_og, (224, 224), interpolation=cv2.INTER_AREA)

    # Show the image in a window
    # cv2.imshow("Webcam Image", image_og)
    # cv2.imshow("Image", image)
    # Make the image a numpy array and reshape it to the models input shape.
    image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)

    # Normalize the image array
    image = (image / 127.5) - 1 # model / 255 * 2 -1

    # Predicts the model
    prediction = model.predict(image)
    index = np.argmax(prediction)
    class_name = class_names[index]
    # ["0, class_1", "1, class_2", "2, class_3"]
    confidence_score = prediction[0][index]

    if confidence_score < 0.8:
        text = "I don't know."

    else:
    # Print prediction and confidence score
        name = str(class_name[2:])
        result = str(np.round(confidence_score * 100))[:-2] + "%"
        text = name + " " + result
    print("Class:", name, end="")
    print("Confidence Score:", result)
    cv2.putText(image_og, text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    cv2.imshow("Webcam Image", image_og)
    # Listen to the keyboard for presses.
    keyboard_input = cv2.waitKey(1)
    # 27 is the ASCII for the esc key on your keyboard.
    if keyboard_input == 27:
        break

camera.release()
cv2.destroyAllWindows()
```


